#!/usr/bin/env python3
'''
Run from cache:
python -m raggen \
    --output_folder="./outputs" \
    --rag_file="rag_data_100.txt" \
    --model_checkpoint=68000 \
    --num_instructions=100
'''

import argparse
import os
import re

import tqdm
from cache import Cache
import torch
from cache_replacement.policy_learning.cache.memtrace import MemoryTrace
from cache_replacement.policy_learning.cache.eviction_policy import BeladyScorer, GreedyEvictionPolicy, LRUScorer
from cache_replacement.policy_learning.cache_model.eviction_policy import LearnedScorer
from cache_replacement.policy_learning.common import config as cfg
from cache_replacement.policy_learning.cache_model import metric, model, schedules, utils
from cache_replacement.policy_learning.cache_model import model
from task02 import model02
from task03 import model03
from task04 import model04



class CacheObserver:
    def __init__(self, multiplier=1):
        self.reset()
        self.num_instructions = 1_000_000_000  # champsim simulates this number of instructions and than crashes
        self.multiplier = multiplier

    def update(self, hit):
        self.cache_hits += int(hit)
        self.cache_accesses += 1

    def reset(self):
        self.cache_accesses = 0
        self.cache_hits = 0

    @property
    def cache_misses(self):
        return self.cache_accesses - self.cache_hits

    def compute_mpki(self):
        return (self.cache_misses * self.multiplier / self.num_instructions) * 1000

    def compute_hit_rate(self):
        return self.cache_hits / self.cache_accesses


def main(args: argparse.Namespace):
    # Number of instructions to run
    max_read_idx = args.num_instructions - 1

    # Cache config
    cache_config = {"cache_line_size": 64, "capacity": 64 * 16 * 64, "associativity": 16}

    workloads = ["traces/astar_313B_test.csv",
                 "traces/lbm_564B_test.csv",
                 "traces/mcf_250B_test.csv",
                 "traces/milc_409B_test.csv",
                 "traces/omnetpp_4B_test.csv"]
    
    pattern = r"traces/([^_]+)_"
    for workloadNum, workload in enumerate(workloads):

        # Determine number of cache accesses 
        num_cache_accesses = sum(1 for _ in open(workload))

        workloadName = workload.split('/')[1].split('_')[0]

        # Load memory trace into memory
        # Make sure the trace_file is the 'llm_access_trace.csv' file as generated by champsim
        memtrace = MemoryTrace(workload, cache_line_size=cache_config["cache_line_size"], max_look_ahead=int(1e5))

        # Initialize Belady's optimal eviction policy
        belady_scorer = BeladyScorer(memtrace)
        belady_policy = GreedyEvictionPolicy(belady_scorer)

        # Initialize LRU eviction policy
        lru_scorer = LRUScorer()
        lru_policy = GreedyEvictionPolicy(lru_scorer)

        # Model configs
        model_0203_config = ["configs/model02-03_config.json"]
        model_0203_config = cfg.Config.from_files_and_bindings(model_0203_config, [])

        default_config = ["configs/default.json"]
        default_config = cfg.Config.from_files_and_bindings(default_config, [])

        # Load checkpoints into memory
        checkpoint = args.model_checkpoint
        t2astar_ckpt = "checkpoints/t2astar3" + f"_{checkpoint}.ckpt"
        t3astar_ckpt = "checkpoints/t3astar3" + f"_{checkpoint}.ckpt"
        t4astar_ckpt = "checkpoints/t4astar3" + f"_{checkpoint}.ckpt"

        # Initialize task02-04 eviction policies
        t2_model = model02.EvictionPolicyModel.from_config(model_0203_config)
        if t2astar_ckpt is not None:
            with open(t2astar_ckpt, "rb") as f:
                t2_model.load_state_dict(torch.load(f, map_location=torch.device('cpu')))
        t2_scorer = LearnedScorer(t2_model)
        t2_policy = GreedyEvictionPolicy(t2_scorer)

        t3_model = model03.EvictionPolicyModel.from_config(model_0203_config)
        if t3astar_ckpt is not None:
            with open(t3astar_ckpt, "rb") as f:
                t3_model.load_state_dict(torch.load(f, map_location=torch.device('cpu')))
        t3_scorer = LearnedScorer(t3_model)
        t3_policy = GreedyEvictionPolicy(t3_scorer)

        t4_model = model04.EvictionPolicyModel.from_config(default_config)
        if t4astar_ckpt is not None:
            with open(t4astar_ckpt, "rb") as f:
                t4_model.load_state_dict(torch.load(f, map_location=torch.device('cpu')))
        t4_scorer = LearnedScorer(t4_model)
        t4_policy = GreedyEvictionPolicy(t4_scorer)

        # Initialize observers
        lru_observer = CacheObserver()
        t2_observer = CacheObserver()
        t3_observer = CacheObserver()
        t4_observer = CacheObserver()

        belady_lru_observer = CacheObserver()
        belady_t2_observer = CacheObserver() # NOTE: not sure if this is necessary
        belady_t3_observer = CacheObserver()
        belady_t4_observer = CacheObserver()

        # Initialize caches
        lru_cache = Cache.from_config(cache_config, eviction_policy=lru_policy)
        t2_cache = Cache.from_config(cache_config, eviction_policy=t2_policy)
        t3_cache = Cache.from_config(cache_config, eviction_policy=t3_policy)
        t4_cache = Cache.from_config(cache_config, eviction_policy=t4_policy)

        assert os.path.exists(args.output_folder), f"Output folder {args.output_folder} does not exist"
        if workloadNum == 0:
            f = open(os.path.join(args.output_folder, args.rag_file), "w")
        else:
            f = open(os.path.join(args.output_folder, args.rag_file), "a")

        read_idx = 0

        # Calculate MPKI and hit rate
        with memtrace:
            for read_idx in tqdm.tqdm(range(num_cache_accesses), desc=f"trace: {workload}"):
                assert not memtrace.done()
                pc, address = memtrace.next()

                # Clone cache with Belady's optimal eviction policy
                belady_lru_cache = lru_cache.clone(belady_policy)
                belady_t2_cache = t2_cache.clone(belady_policy)
                belady_t3_cache = t3_cache.clone(belady_policy)
                belady_t4_cache = t4_cache.clone(belady_policy)

                # Cache hit or miss
                lru_hit = lru_cache.read(pc, address)
                t2_hit = t2_cache.read(pc, address)
                t3_hit = t3_cache.read(pc, address)
                t4_hit = t4_cache.read(pc, address)

                # Update observers
                lru_observer.update(lru_hit)
                t2_observer.update(t2_hit)
                t3_observer.update(t3_hit)
                t4_observer.update(t4_hit)

                belady_lru_observer.update(belady_lru_cache.read(pc, address))
                belady_t2_observer.update(belady_t2_cache.read(pc, address))
                belady_t3_observer.update(belady_t3_cache.read(pc, address))
                belady_t4_observer.update(belady_t4_cache.read(pc, address))

                # Default to no evicted line
                lru_eviction = None
                t2_eviction = None
                t3_eviction = None
                t4_eviction = None

                belady_lru_eviction = None
                belady_t2_eviction = None
                belady_t3_eviction = None
                belady_t4_eviction = None

                # Get evicted line
                if not lru_hit and lru_cache.last_evicted_cache_line is not None:
                    lru_eviction = hex(lru_cache.last_evicted_cache_line)
                    belady_lru_eviction = hex(belady_lru_cache.last_evicted_cache_line)
                
                if not t2_hit and t2_cache.last_evicted_cache_line is not None:
                    t2_eviction = hex(t2_cache.last_evicted_cache_line)
                    belady_t2_eviction = hex(belady_t2_cache.last_evicted_cache_line)
                    
                if not t3_hit and t3_cache.last_evicted_cache_line is not None:
                    t3_eviction = hex(t3_cache.last_evicted_cache_line)
                    belady_t3_eviction = hex(belady_t3_cache.last_evicted_cache_line)

                if not t2_hit and t2_cache.last_evicted_cache_line is not None:
                    t4_eviction = hex(t4_cache.last_evicted_cache_line)
                    belady_t4_eviction = hex(belady_t4_cache.last_evicted_cache_line)

                f.write(
                        f"Workload: {workloadName} |"
                        f"PC: {hex(pc)} |"
                        f"Belady Evicted: {belady_lru_eviction} |"
                        f"LRU Evicted: {lru_eviction} |"
                        f"Policy02 Evicted: {t2_eviction} | Belady02 Evicted: {belady_t2_eviction} |"
                        f"Policy03 Evicted: {t3_eviction} | Belady03 Evicted: {belady_t3_eviction} |"
                        f"Policy04 Evicted: {t4_eviction} | Belady04 Evicted: {belady_t4_eviction}\n"
                )


                if read_idx == max_read_idx: # Number of instructions to run
                    break
    f.close()

    # Compute mpki
    lru_mpki = lru_observer.compute_mpki()
    t2_mpki = t2_observer.compute_mpki()
    t3_mpki = t3_observer.compute_mpki()
    t4_mpki = t4_observer.compute_mpki()

    lru_hit_rate = lru_observer.compute_hit_rate() * 100
    t2_hit_rate = t2_observer.compute_hit_rate() * 100
    t3_hit_rate = t2_observer.compute_hit_rate() * 100
    t4_hit_rate = t2_observer.compute_hit_rate() * 100

    print(f"From stats: {lru_cache.hit_rate_statistic.success_rate() * 100 }\n")
    print(f"LRU MPKI: {lru_mpki}, Hit rate: {lru_hit_rate}\n")
    print(f"Task02 MPKI: {t2_mpki}, Hit rate: {t2_hit_rate}\n")
    print(f"Task03 MPKI: {t3_mpki}, Hit rate: {t3_hit_rate}\n")
    print(f"Task04 MPKI: {t4_mpki}, Hit rate: {t4_hit_rate}\n")
    


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument("--output_folder", type=str, default="./outputs")
    parser.add_argument("--rag_file", type=str, default="rag_data.txt")
    parser.add_argument("--model_checkpoint", type=int, default=68000)
    parser.add_argument("--num_instructions", type=int, default=1000)
    args = parser.parse_args()

    main(args)
